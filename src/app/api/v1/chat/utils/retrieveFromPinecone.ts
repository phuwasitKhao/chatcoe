// src/api/v1/chat/utils/retrieveFromPinecone.ts
import { Pinecone } from '@pinecone-database/pinecone'

import pinecone from "./pineconeClient"; // default import ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
import { OpenAI } from "openai";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

export async function retrieveContextFromData(
    query: string,
    namespace = "default"
): Promise<string> {
    try {
        // ‚úÖ Ensure Pinecone is initialized (‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ init ‡∏ó‡∏µ‡πà‡∏≠‡∏∑‡πà‡∏ô)
        const pc = new Pinecone({
            apiKey: process.env.PINECONE_API_KEY!,
        });

        const index = pinecone.Index(process.env.PINECONE_INDEX_NAME!);

        // üîç Embed query
        const embeddingResponse = await openai.embeddings.create({
            input: query,
            model: "text-embedding-3-small",
        });

        const vector = embeddingResponse.data[0].embedding;

        // üîç ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Pinecone
        const result = await index.query({
            vector,
            topK: 3,
            includeMetadata: true,
        });

        const texts = result.matches
            ?.map((m) => m.metadata?.text)
            .filter(Boolean);

        return texts?.join("\n---\n") || "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á";
    } catch (err: any) {
        console.error("üî¥ retrieveContextFromData error:", err?.message || err);
        return "‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Pinecone ‡∏´‡∏£‡∏∑‡∏≠‡∏ù‡∏±‡πà‡∏á Embedding";
    }
}
